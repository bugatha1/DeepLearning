{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxUUveudcQZEWAAi8JRA9b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bugatha1/DeepLearning/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Networks\n",
        "\n",
        "Neural networks learn to recognize patterns from existing data. This is we called training.\n",
        "\n",
        "weight = round * shape weight +  red * color weight                             \n",
        "      = (1 * 2) + (1 * 3)                                                       \n",
        "      = 6                                                                      \n",
        "      \n",
        "First we need to define the **threshold value**                                 \n",
        " output =  0 for banana                                                         \n",
        "          1 for orange                                                          \n",
        "          \n",
        "The output is determied based on the threshold value                            \n",
        "Let's say the **threshold value** = 3                                           \n",
        "\n",
        "output = 0 if total weight < 3 -> banana                                        \n",
        "         1 if total weight >= 3 -> orange\n"
      ],
      "metadata": {
        "id": "9YmTEM9kTIAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Functions                                                          \n",
        "It helps neuron to learn and make predictions                                   \n",
        "It introduces non linear properties to our network"
      ],
      "metadata": {
        "id": "WhFIDRG-Uwi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Threshold Function**\n",
        "\n",
        "If x < 0 = 0                                                                    \n",
        "If x >= 0 = 1                                                                   \n",
        "This function return 0 if x less than 0 or 1 if x greater or equal 0. "
      ],
      "metadata": {
        "id": "N_M4VcyOTMdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sigmoid Function**\n",
        "\n",
        "It generates value between 0 and 1. It's a non linear function.                 \n",
        "It uses in classification problems.\n",
        "\n",
        "x = 1/(1+pow-1(e)) "
      ],
      "metadata": {
        "id": "vLXkkeY-Uu9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperbolic Tangent(Tanh)**                                                \n",
        "It generates value between -1 and 1. It is non linear function.                 \n",
        "x = (1 - (e powerof -2x))/(1 + (e powerof -2x))"
      ],
      "metadata": {
        "id": "odnHaJplZgKg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ReLu (Rectifier Linear Unit)**\n",
        "It generates 0 if the input is less than 0. Otherwise the output as the same as the input.                                                                      \n",
        "ReLu is computationally efficient.\n",
        "\n",
        "x = max(x, 0)"
      ],
      "metadata": {
        "id": "i3cflq7-VNNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cost Functions\n",
        "\n",
        "In neural network cost function refers loss                                    \n",
        "C = sum(1/2(y^ - y)power2)                                                      \n",
        "\n",
        "We can minimize the cost function by using Gradient Descent and Back propagation\n",
        "algorithms.\n"
      ],
      "metadata": {
        "id": "G8NWwvi6Z3iY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent\n",
        "\n",
        "It is used to optimize cost function.\n",
        "Desending towards minimum of the cost function.\n",
        "It minimize the cost function value by existing weights"
      ],
      "metadata": {
        "id": "XWIg3PxstLD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traninig the ANN with Stochastic Gradient descent\n",
        "\n",
        "step1 : Ramdomly initialise the weights to small number close to 0 (but not 0). \n",
        "step2 : Input the first observation of your dataset in the input layer, each feature is one input in node.                                                   \n",
        "step3: Forward-propagation: from left to right, the neurons activated in a way that the impact of each neuron's activation is limited by the weights. Propagate the activations until getting the predicted results.                  \n",
        "step4: Compare the predicted result with actual result. Measure the generated error.\n",
        "step5: Back-propagation: from right to left the error is back propagated. Update the weights according to how much they are responsible for the error. The learning rate decides by how much we updated the weights.                  \n",
        "step6: Repeat step 1 to 5  and update the weights after each observation(Reinforcement learning) Or Repeat steps 1 to 5 but update the weights only after a batch of observations (Batch learning)                                 \n",
        "step7 : When the whole training set passed through the ANN, that makes an epoch. Redo more epochs \n"
      ],
      "metadata": {
        "id": "_dc6X5ZyS4Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buid the ANN\n",
        "import tensorflow as tf\n",
        "\n",
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "JlBO8nlgcmeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HcN904CmYdrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "id": "csG2LPMGYtrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict([[X_test]])"
      ],
      "metadata": {
        "id": "tKhTjQSUZJlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution Neural Networks"
      ],
      "metadata": {
        "id": "DbzxiF6-hEtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "on input image we apply multiple different feature detectors(filters) to create feature maps, this compresess our convolution layer. On convolution layer we apply 'relu' activation function to remove linearity and increase non linearity in our images then we applied a pooling layer on our convolution layer, so for every feature map we will create pooled feature map . It will reduce the size and avoiding any kind of overfitting . Basically if our images flipped, twisted still we pick the features . Then it will be flatten and input the ANN."
      ],
      "metadata": {
        "id": "6s9Bs9LePQ7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "sEUVv3oXlmeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(\n",
        "    'dataset/training_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "isogWXILnENC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    'dataset/test_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "UedYpv-anPfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.model.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filter=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filter=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=28, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "iClQN7KinpsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NOBqru62qCwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = train_set, validation_data = test_set, epochs=25)"
      ],
      "metadata": {
        "id": "QgIc3XQEqQ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load('', target_size=(64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "result = cnn.predict(test_image)\n",
        "\n"
      ],
      "metadata": {
        "id": "F7WqG0KSrB7v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}