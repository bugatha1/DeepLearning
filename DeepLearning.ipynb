{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPUp3JfjC13ftGOKJfSYns6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bugatha1/DeepLearning/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Functions"
      ],
      "metadata": {
        "id": "9YmTEM9kTIAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Threshold Function\n",
        "\n",
        "If x < 0 = 0                                                                    \n",
        "If x >= 0 = 1                                                                   \n",
        "This function return 0 if x less than 0 or 1 if x greater or equal 0. "
      ],
      "metadata": {
        "id": "N_M4VcyOTMdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sigmoid Function\n",
        "\n",
        "x = 1/(1+pow-1(e)) "
      ],
      "metadata": {
        "id": "vLXkkeY-Uu9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rectifier Function\n",
        "\n",
        "x = max(x, 0)"
      ],
      "metadata": {
        "id": "i3cflq7-VNNF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperbolic Tangent(Tanh)\n",
        "\n",
        "x = (1 - (e powerof -2x))/(1 + (e powerof -2x))"
      ],
      "metadata": {
        "id": "3VWYqekPVfk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross Functions\n",
        "\n",
        "In neural network cross function refers loss                                    \n",
        "C = sum(1/2(y^ - y)power2)\n"
      ],
      "metadata": {
        "id": "G8NWwvi6Z3iY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Descent\n",
        "\n",
        "Desending towards minimum of the cross function.\n",
        "It minimize the cross function value by existing weights"
      ],
      "metadata": {
        "id": "XWIg3PxstLD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Traninig the ANN with Stochastic Gradient descent\n",
        "\n",
        "step1 : Ramdomly initialise the weights to small number close to 0 (but not 0). \n",
        "step2 : Input the first observation of your dataset in the input layer, each feature is one input in node.                                                   \n",
        "step3: Forward-propagation: from left to right, the neurons activated in a way that the impact of each neuron's activation is limited by the weights. Propagate the activations until getting the predicted results.                  \n",
        "step4: Compare the predicted result with actual result. Measure the generated error.\n",
        "step5: Back-propagation: from right to left the error is back propagated. Update the weights according to how much they are responsible for the error. The learning rate decides by how much we updated the weights.                  \n",
        "step6: Repeat step 1 to 5  and update the weights after each observation(Reinforcement learning) Or Repeat steps 1 to 5 but update the weights only after a batch of observations (Batch learning)                                 \n",
        "step7 : When the whole training set passed through the ANN, that makes an epoch. Redo more epochs \n"
      ],
      "metadata": {
        "id": "_dc6X5ZyS4Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Buid the ANN\n",
        "import tensorflow as tf\n",
        "\n",
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "JlBO8nlgcmeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "HcN904CmYdrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "id": "csG2LPMGYtrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict([[X_test]])"
      ],
      "metadata": {
        "id": "tKhTjQSUZJlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution Neural Networks"
      ],
      "metadata": {
        "id": "DbzxiF6-hEtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "on input image we apply multiple different feature detectors(filters) to create feature maps, this compresess our convolution layer. On convolution layer we apply 'relu' activation function to remove linearity and increase non linearity in our images then we applied a pooling layer on our convolution layer, so for every feature map we will create pooled feature map . It will reduce the size and avoiding any kind of overfitting . Basically if our images flipped, twisted still we pick the features . Then it will be flatten and input the ANN."
      ],
      "metadata": {
        "id": "6s9Bs9LePQ7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "sEUVv3oXlmeJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(\n",
        "    'dataset/training_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "isogWXILnENC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    'dataset/test_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "id": "UedYpv-anPfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.model.Sequential()\n",
        "cnn.add(tf.keras.layers.Conv2D(filter=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Conv2D(filter=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "cnn.add(tf.keras.layers.Flatten())\n",
        "cnn.add(tf.keras.layers.Dense(units=28, activation='relu'))\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "iClQN7KinpsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NOBqru62qCwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = train_set, validation_data = test_set, epochs=25)"
      ],
      "metadata": {
        "id": "QgIc3XQEqQ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load('', target_size=(64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "result = cnn.predict(test_image)\n",
        "\n"
      ],
      "metadata": {
        "id": "F7WqG0KSrB7v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}